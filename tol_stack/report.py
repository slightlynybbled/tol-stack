from io import BytesIO
from datetime import datetime

from fpdf import FPDF
from PIL import Image

from tol_stack.stack import StackPath
from tol_stack.version import __version__


class StackupReport(FPDF):
    MARGIN = 0.5
    PAGE_HEIGHT = 11
    PAGE_WIDTH = 8.5
    USABLE_WIDTH = PAGE_WIDTH - (2 * MARGIN)

    _heading_font_sizes = [16, 14, 12, 10]
    _font_size = 10

    def __init__(self, stackpath: StackPath):
        super().__init__(format='Letter', unit='in')

        self.font_name = 'helvetica'
        self.stackpath = stackpath

        # title page
        self.add_page()
        self.set_font(self.font_name, 'B', self._heading_font_sizes[0])
        self.start_section(name='Stack Description', level=0)
        self.multi_cell(0, txt=f'{stackpath.name}', align='L')

        self.set_font(self.font_name, '', self._font_size)
        self.ln()
        self.start_section(name='Metadata', level=1)

        self.multi_cell(0,
                        txt=f'Report generated by Tolerence Stack Analyzer v{__version__} on {datetime.now()}',
                        align='L')

        if self.stackpath.description is not None:
            self.ln()
            self.start_section(name='Description', level=1)
            self.multi_cell(0, txt=f'{self.stackpath.description}', align='L', ln=1)

        if self.stackpath.images is not None:
            for image in self.stackpath.images:
                self.image(image)

        # create a part-by-part max/min length analysis,
        # including comments, pictures, and distributions
        self.start_section(name='Part Analysis', level=0)
        for part in self.stackpath.parts:
            self.add_page()
            self.start_section(name=f'{part.name}', level=1)
            self.set_font(self.font_name, "B", self._font_size)
            self.multi_cell(0, txt=f'{part.name}', ln=1)

            self.set_font(self.font_name, "", self._font_size)
            if part.nominal_length is not None:
                self.multi_cell(0, txt=f'nominal length: {part.nominal_length}', ln=1)
            if part.tolerance is not None:
                self.multi_cell(0, txt=f'tolerance: {part.tolerance}', ln=1)

            if part.images is not None:
                for image in part.images:
                    width, height = image.size
                    max_height = 180
                    if height > max_height:
                        new_width = width * max_height // height
                        new_height = max_height
                        image.thumbnail((new_width, new_height), Image.ANTIALIAS)
                    self.image(image)

            if part.comment is not None:
                self.multi_cell(0, txt=f'{part.comment}', ln=1)

            # show part distribution
            buffer = BytesIO()
            fig = part.show_length_dist()
            fig.savefig(buffer, format='png')
            self.image(buffer, w=self.epw)

        # show relative distributions
        self.start_section(name='Relative Part Tolerance Contributions', level=0)
        buffer = BytesIO()
        fig = self.stackpath.show_part_relative_dists()
        fig.savefig(buffer, format='png')
        self.image(buffer, h=self.epw)

        # create stack path analysis
        self.start_section(name='Stackup Summary', level=0)
        buffer = BytesIO()
        fig = self.stackpath.show_length_dist()
        fig.savefig(buffer, format='png')
        self.image(buffer, h=self.epw)

        self.output(f'{self.stackpath.name}.pdf')






